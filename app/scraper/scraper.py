# scraper/scraper.py
import logging
from .utils import format_url, setup_logging
from .browser import get_driver
from .extract import extract_links, extract_text, extract_visible_text
from .actions import hover_over_dropdowns
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# âœ… Initialize logging
setup_logging()

def detect_navbar(url, use_visible_text=False):
    """Extracts website links, files, and all text from the page."""
    logging.info(f"ğŸ” [START] Website link detection for: {url}")

    # âœ… Format URL before proceeding
    url = format_url(url)
    logging.info(f"ğŸŒ Formatted URL: {url}")

    # âœ… Initialize WebDriver
    driver = get_driver()
    logging.info("ğŸ–¥ï¸ WebDriver initialized successfully.")

    try:
        # âœ… Open the website
        logging.info("ğŸŒ Opening website in browser...")
        driver.get(url)

        # âœ… Wait until page fully loads
        logging.info("â³ Waiting for page to fully load...")
        WebDriverWait(driver, 10).until(
            lambda d: d.execute_script("return document.readyState") == "complete"
        )
        logging.info("âœ… Page loaded successfully.")

        # âœ… Start interaction with dropdowns
        logging.info("ğŸ–±ï¸ Hovering over dropdown menus...")
        hover_over_dropdowns(driver)

        # âœ… Extract all links
        logging.info("ğŸ”— Extracting all links from the page...")
        structured_links = extract_links(driver)
        logging.info(f"âœ… Link extraction complete. Found {len(structured_links['navbar_links'])} navbar links and {len(structured_links['file_links'])} file links.")

        # âœ… Extract page text
        logging.info("ğŸ“œ Extracting page text content...")
        if use_visible_text:
            logging.info("ğŸ§ Using **VISIBLE TEXT ONLY** mode...")
            page_text = extract_visible_text(driver)
        else:
            logging.info("ğŸ“– Extracting **ALL TEXT**, including hidden sections...")
            page_text = extract_text(driver)

        logging.info(f"âœ… Text extraction complete. Extracted {len(page_text)} characters.")

    except Exception as e:
        logging.error(f"âŒ An error occurred during scraping: {e}")

    finally:
        logging.info("ğŸ›‘ Closing WebDriver session...")
        driver.quit()
        logging.info("âœ… WebDriver closed.")

    logging.info("ğŸ¯ [FINISHED] Website scraping completed.")

    return {
        "navbar_links": structured_links["navbar_links"],
        "file_links": structured_links["file_links"],
        "page_text": page_text  # âœ… Include extracted text in the response
    }
